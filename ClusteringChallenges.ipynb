{
 "metadata": {
  "name": "",
  "signature": "sha256:d0135931c561a192476163e8f2cd051e64fe2a63d778374aba60068e1883a647"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from pymongo import MongoClient\n",
      "\n",
      "from collections import defaultdict\n",
      "import operator\n",
      "\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.cluster import MiniBatchKMeans,KMeans\n",
      "from sklearn.metrics import pairwise_distances\n",
      "\n",
      "from nltk.tokenize import word_tokenize\n",
      "from nltk.tag import pos_tag\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.chunk import ne_chunk\n",
      "\n",
      "\n",
      "from textblob import TextBlob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "client = MongoClient('mongodb://localhost:27017/')\n",
      "db = client.Fletcher_db\n",
      "collection = db.presidential_articles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles = []\n",
      "cursor = collection.find()\n",
      "for c in cursor:\n",
      "    articles.append(c)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles_1000 = articles[:1000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "headlines = []\n",
      "for a in articles_1000:\n",
      "    headlines.append(a['headline']['main'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Challenge 1\n",
      "\n",
      "Cluster sentences with K-means. If you have your own Fletcher test data, get sentences out and cluster them. If not, cluster the tweets you gathered during the Twitter API challenge. For each cluster, print out the sentences, try to see how close the sentences are. Try different K values and try to find a K value that makes the most sense (the sentences look like they do form a meaningful cluster).\n",
      "\n",
      "How do you deal with retweets if you're clustering tweets?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2))\n",
      "headlines_vectors = vectorizer.fit_transform(headlines)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_clusters = 5\n",
      "k_means = KMeans(n_clusters=num_clusters)\n",
      "clusters = k_means.fit_predict(headlines_vectors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cluster_dict = defaultdict(list)\n",
      "for i,h in enumerate(headlines):\n",
      "    cluster_dict[clusters[i]].append(h)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Challenge 2\n",
      "\n",
      "Draw the inertia curve over different k values. (Sklearn KMeans class has an inertia_ attribute)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inertia = []\n",
      "for n_clusters in range(1,20):\n",
      "    k_means = KMeans(n_clusters=n_clusters)\n",
      "    clusters = k_means.fit_predict(headlines_vectors)\n",
      "    inertia.append(k_means.inertia_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(range(1,20),inertia)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "[<matplotlib.lines.Line2D at 0x15c41ed50>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWPz2cilRAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x15c414390>"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Challenge 3\n",
      "\n",
      "Let's name the clusters 1\n",
      "For each cluster, find the sentence closest to the centroid of the (You can learn sklearn.metrics.pairwise_distances or scipy.spatial.distance (check pdist, cdist, and euclidean distance) to find distances to the centroid. KMeans has a cluster_centroids_ attribute. This sentence (closest to centroid) is now the name of the cluster. For each cluster, print the representative sentence, and print 'N people expressed a similar statement', or something like that relevant to your dataset. (This is very close to what amazon used to do in the reviews section up to a year ago.)\n",
      "\n",
      "Find the biggest 3 clusters, and print their representative sentences (This is close to what amazon is doing now in the reviews section, except they choose the sentence from the most helpful review instead of closest to center)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = TfidfVectorizer(stop_words='english',ngram_range=(1,2))\n",
      "headlines_vectors = vectorizer.fit_transform(headlines)\n",
      "num_clusters = 10\n",
      "k_means = KMeans(n_clusters=num_clusters)\n",
      "clusters = k_means.fit_predict(headlines_vectors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def min_or_not_empty(l1,l2):\n",
      "    if len(l1)==0:\n",
      "        return l2\n",
      "    elif len(l2)==0:\n",
      "        return l1\n",
      "    else:\n",
      "        return min(l1,l2)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cluster_centers = k_means.cluster_centers_\n",
      "c_dict = defaultdict(tuple) # (min_dist,index)\n",
      "for i,c in enumerate(clusters):\n",
      "    c_dict[c] = min_or_not_empty(c_dict[c],(float(pairwise_distances(headlines_vectors[i],cluster_centers[c])),i))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for c in range(num_clusters):\n",
      "    print c, headlines[c_dict[c][1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 The I's Have It\n",
        "1 Senate Confirms Geithner as Treasury Secretary\n",
        "2 WHAT'S ON TODAY\n",
        "3 Early Word\n",
        "4 President Obama\n",
        "5 Get Out of the (White) House\n",
        "6 INSIDE THE TIMES: February 9, 2009\n",
        "7 Obama in Canada\n",
        "8 The First 100 Days Edition\n",
        "9 Obama Signs Stimulus Plan\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Challenge 4\n",
      "\n",
      "Let's name the clusters 2\n",
      "Calculate the tf-idf of each word in each cluster (think of all sentences of a cluster together as a document). Represent each cluster with the top 1, or top 2 or... to 5 tf-idf words. For each cluster, print the name (keywords) of the cluster, and \"N statements\" in the cluster (N is the size of the cluster)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cluster_dict = defaultdict(list)\n",
      "for i,h in enumerate(headlines):\n",
      "    cluster_dict[clusters[i]].append(h)\n",
      "\n",
      "combined_dict = {}\n",
      "for c in cluster_dict.keys():\n",
      "    combined_dict[c]=' '.join(cluster_dict[c])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2))\n",
      "cluster_vectors = vectorizer.fit_transform(combined_dict.values())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cluster_kws = defaultdict(list)\n",
      "for c in cluster_dict.keys():\n",
      "    indices = cluster_vectors[c].indices\n",
      "    data = cluster_vectors[c].data\n",
      "    for kw_index,tfidf in zip(indices,data):\n",
      "        #kw_index = cluster_vectors[c].indices[i]\n",
      "        cluster_kws[c].append((tfidf,vectorizer.get_feature_names()[kw_index]))\n",
      "    cluster_kws[c]=sorted(cluster_kws[c],reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for c in cluster_kws.keys():\n",
      "    print c, [kw[1] for kw in cluster_kws[c][:5]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 [u'stimulus', u'new', u'money', u'day', u'com']\n",
        "1 [u'senate', u'geithner', u'secretary', u'treasury', u'choice']\n",
        "2 [u'today', u'today today', u'today business', u'business today', u'business']\n",
        "3 [u'word', u'early word', u'early', u'saturday word', u'saturday']\n",
        "4 [u'president obama', u'president', u'obama', u'budget president', u'budget']\n",
        "5 [u'white house', u'white', u'house', u'house white', u'spray']\n",
        "6 [u'inside times', u'2009 inside', u'2009', u'inside', u'times']\n",
        "7 [u'obama', u'stimulus', u'new', u'bush', u'michelle obama']\n",
        "8 [u'days', u'days edition', u'100 days', u'edition', u'100']\n",
        "9 [u'plan', u'obama', u'stimulus plan', u'plan obama', u'bailout plan']\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Challenge 5\n",
      "\n",
      "Let's name the clusters 3\n",
      "Same as the previous challenge, but this time, calculate tf-idf only for nouns (NN tag) and build keyword(s) with nouns. (This is close to what amazon switched to last year, before settling into the current design). (They would show five nouns, you would click on one and it would show sentences - linked to the reviews- that were related to that noun.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cluster_dict = defaultdict(list)\n",
      "for i,h in enumerate(headlines):\n",
      "    cluster_dict[clusters[i]].append(h)\n",
      "    \n",
      "combined_dict={}\n",
      "for c in cluster_dict.keys():\n",
      "    combined_dict[c]=' '.join(cluster_dict[c])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,1))\n",
      "cluster_vectors = vectorizer.fit_transform(combined_dict.values())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cluster_kws = defaultdict(list)\n",
      "for c in cluster_dict.keys():\n",
      "    indices = cluster_vectors[c].indices\n",
      "    data = cluster_vectors[c].data\n",
      "    for kw_index,tfidf in zip(indices,data):\n",
      "        kw_name = vectorizer.get_feature_names()[kw_index]\n",
      "        if pos_tag(kw_name)[0][1]=='NN':\n",
      "            cluster_kws[c].append((tfidf,kw_name))\n",
      "    cluster_kws[c]=sorted(cluster_kws[c],reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for c in cluster_kws.keys():\n",
      "    print c, [kw[1] for kw in cluster_kws[c][:5]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 [u'new', u'money', u'day', u'com', u'chief']\n",
        "1 [u'geithner', u'treasury', u'choice', u'voting', u'lukewarm']\n",
        "2 [u'today', u'mr', u'president', u'day']\n",
        "3 [u'word', u'early', u'obama', u'new', u'wreck']\n",
        "4 [u'president', u'obama', u'releases', u'economy', u'day']\n",
        "5 [u'white', u'house', u'revise', u'loosens', u'lawn']\n",
        "6 [u'times', u'february', u'january']\n",
        "7 [u'obama', u'new', u'michelle', u'makes', u'vows']\n",
        "8 [u'days', u'edition', u'msnbc', u'riveting', u'tales']\n",
        "9 [u'plan', u'obama', u'housing', u'withdrawal', u'recovery']\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Challenge 6\n",
      "\n",
      "Cluster the same data with MiniBatchKMeans. MiniBatchKMeans is a fast way to apply K-means to large data without much loss -- The results are very similar. Instead of using EVERY single point to find the new place of the centroid, MiniBatch just randomly samples a small number (like 100) in the cluster to calculate the new center. Since this is usually very close to the actual center, the algorithm gets there much faster. Try it and compare the results. Example on two-feature data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = TfidfVectorizer(stop_words='english',ngram_range=(1,2))\n",
      "headlines_vectors = vectorizer.fit_transform(headlines)\n",
      "num_clusters = 10\n",
      "mini_k_means = MiniBatchKMeans(n_clusters=num_clusters)\n",
      "clusters = mini_k_means.fit_predict(headlines_vectors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cluster_dict_mini = defaultdict(list)\n",
      "for i,h in enumerate(headlines):\n",
      "    cluster_dict_mini[clusters[i]].append(h)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Challenge 7\n",
      "\n",
      "Switch the init parameter to \"random\" (instead of the default kmeans++) and plot the inertia curve for each of the n_init values for K-Means: 1, 2, 3, 10 (n_init is the number of different runs to try with different random initializations)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inertia = []\n",
      "for n_clusters in range(20):\n",
      "    k_means = KMeans(n_clusters=n_clusters,)\n",
      "    clusters = k_means.fit_predict(headlines_vectors)\n",
      "    inertia.append(k_means.inertia_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}